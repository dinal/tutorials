{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclio - Data preperation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nuclio in /conda/envs/rapids/lib/python3.6/site-packages (0.1.0)\n",
      "Requirement already satisfied: nuclio-jupyter in /conda/envs/rapids/lib/python3.6/site-packages (0.7.3)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio) (4.3.2)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio) (1.0.0)\n",
      "Requirement already satisfied: ipython>=6.4.0 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio) (7.3.0)\n",
      "Requirement already satisfied: nbconvert>=5.4 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (5.5.0)\n",
      "Requirement already satisfied: tornado<6,>=5 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (5.1.1)\n",
      "Requirement already satisfied: nuclio-sdk>=0.0.3 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (0.0.5)\n",
      "Requirement already satisfied: jupyterlab>=0.35.4 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (0.35.6)\n",
      "Requirement already satisfied: requests>=2.20.1 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (2.22.0)\n",
      "Requirement already satisfied: boto3>=1.9 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (1.9.158)\n",
      "Requirement already satisfied: notebook>=5.7.2 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (5.7.8)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /conda/envs/rapids/lib/python3.6/site-packages (from nuclio-jupyter) (5.1)\n",
      "Requirement already satisfied: ipython_genutils in /conda/envs/rapids/lib/python3.6/site-packages (from traitlets>=4.3.2->nuclio) (0.2.0)\n",
      "Requirement already satisfied: six in /conda/envs/rapids/lib/python3.6/site-packages (from traitlets>=4.3.2->nuclio) (1.12.0)\n",
      "Requirement already satisfied: decorator in /conda/envs/rapids/lib/python3.6/site-packages (from traitlets>=4.3.2->nuclio) (4.4.0)\n",
      "Requirement already satisfied: qtconsole in /conda/envs/rapids/lib/python3.6/site-packages (from jupyter>=1.0.0->nuclio) (4.5.1)\n",
      "Requirement already satisfied: ipywidgets in /conda/envs/rapids/lib/python3.6/site-packages (from jupyter>=1.0.0->nuclio) (7.4.2)\n",
      "Requirement already satisfied: jupyter-console in /conda/envs/rapids/lib/python3.6/site-packages (from jupyter>=1.0.0->nuclio) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /conda/envs/rapids/lib/python3.6/site-packages (from jupyter>=1.0.0->nuclio) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (41.0.1)\n",
      "Requirement already satisfied: jedi>=0.10 in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (0.13.3)\n",
      "Requirement already satisfied: pickleshare in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (0.7.5)\n",
      "Requirement already satisfied: prompt_toolkit<2.1.0,>=2.0.0 in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (2.0.9)\n",
      "Requirement already satisfied: pygments in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (2.4.0)\n",
      "Requirement already satisfied: backcall in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /conda/envs/rapids/lib/python3.6/site-packages (from ipython>=6.4.0->nuclio) (4.7.0)\n",
      "Requirement already satisfied: testpath in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (0.4.2)\n",
      "Requirement already satisfied: bleach in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (1.4.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (4.4.0)\n",
      "Requirement already satisfied: defusedxml in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (0.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (0.3)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /conda/envs/rapids/lib/python3.6/site-packages (from nbconvert>=5.4->nuclio-jupyter) (2.10.1)\n",
      "Requirement already satisfied: jupyterlab_server<0.3.0,>=0.2.0 in /conda/envs/rapids/lib/python3.6/site-packages (from jupyterlab>=0.35.4->nuclio-jupyter) (0.2.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.20.1->nuclio-jupyter) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.20.1->nuclio-jupyter) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.20.1->nuclio-jupyter) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.20.1->nuclio-jupyter) (2019.3.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /conda/envs/rapids/lib/python3.6/site-packages (from boto3>=1.9->nuclio-jupyter) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /conda/envs/rapids/lib/python3.6/site-packages (from boto3>=1.9->nuclio-jupyter) (0.2.0)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.158 in /conda/envs/rapids/lib/python3.6/site-packages (from boto3>=1.9->nuclio-jupyter) (1.12.158)\n",
      "Requirement already satisfied: pyzmq>=17 in /conda/envs/rapids/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter) (18.0.1)\n",
      "Requirement already satisfied: prometheus-client in /conda/envs/rapids/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter) (0.6.0)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /conda/envs/rapids/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter) (5.2.4)\n",
      "Requirement already satisfied: Send2Trash in /conda/envs/rapids/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /conda/envs/rapids/lib/python3.6/site-packages (from notebook>=5.7.2->nuclio-jupyter) (0.8.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /conda/envs/rapids/lib/python3.6/site-packages (from ipywidgets->jupyter>=1.0.0->nuclio) (3.4.2)\n",
      "Requirement already satisfied: parso>=0.3.0 in /conda/envs/rapids/lib/python3.6/site-packages (from jedi>=0.10->ipython>=6.4.0->nuclio) (0.4.0)\n",
      "Requirement already satisfied: wcwidth in /conda/envs/rapids/lib/python3.6/site-packages (from prompt_toolkit<2.1.0,>=2.0.0->ipython>=6.4.0->nuclio) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /conda/envs/rapids/lib/python3.6/site-packages (from pexpect->ipython>=6.4.0->nuclio) (0.6.0)\n",
      "Requirement already satisfied: webencodings in /conda/envs/rapids/lib/python3.6/site-packages (from bleach->nbconvert>=5.4->nuclio-jupyter) (0.5.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /conda/envs/rapids/lib/python3.6/site-packages (from nbformat>=4.4->nbconvert>=5.4->nuclio-jupyter) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /conda/envs/rapids/lib/python3.6/site-packages (from jinja2>=2.4->nbconvert>=5.4->nuclio-jupyter) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /conda/envs/rapids/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.158->boto3>=1.9->nuclio-jupyter) (2.8.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /conda/envs/rapids/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.158->boto3>=1.9->nuclio-jupyter) (0.14)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /conda/envs/rapids/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert>=5.4->nuclio-jupyter) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /conda/envs/rapids/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert>=5.4->nuclio-jupyter) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "!pip install nuclio nuclio-jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.triggers.retrain.kind to 'cron'\n",
      "%nuclio: setting spec.triggers.retrain.attributes.interval to '1h'\n",
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config\n",
    "\n",
    "# Trigger\n",
    "spec.triggers.retrain.kind = \"cron\"\n",
    "spec.triggers.retrain.attributes.interval = \"1h\"\n",
    "\n",
    "# Base image\n",
    "spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "\n",
    "############\n",
    "# installs #\n",
    "############\n",
    "\n",
    "# Utils\n",
    "pip install pyarrow\n",
    "pip install pandas\n",
    "\n",
    "# Igz DB\n",
    "pip install v3io_frames --upgrade\n",
    "\n",
    "# Function\n",
    "pip install dask[\"complete\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 21,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'V3IO_FRAMESD' environment variable\n",
      "%nuclio: setting 'V3IO_USERNAME' environment variable\n",
      "%nuclio: setting 'V3IO_ACCESS_KEY' environment variable\n",
      "%nuclio: setting 'SAVE_TO_TSDB' environment variable\n",
      "%nuclio: setting 'METRICS_TABLE' environment variable\n",
      "%nuclio: setting '# METRICS_TABLE' environment variable\n",
      "%nuclio: setting 'FEATURES_TABLE' environment variable\n",
      "%nuclio: setting '# FEATURES_TABLE' environment variable\n",
      "%nuclio: setting 'NUMBER_OF_SHARDS' environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n"
     ]
    }
   ],
   "source": [
    "%%nuclio env\n",
    "\n",
    "# DB Config\n",
    "V3IO_FRAMESD=${V3IO_FRAMESD}\n",
    "V3IO_USERNAME=${V3IO_USERNAME}\n",
    "V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "\n",
    "# Save as\n",
    "SAVE_TO_TSDB=0\n",
    "\n",
    "# Metrics\n",
    "METRICS_TABLE=netops_metrics\n",
    "# METRICS_TABLE=/v3io/bigdata/netops_metrics_parquet\n",
    "\n",
    "# Features\n",
    "FEATURES_TABLE=netops_features\n",
    "# FEATURES_TABLE=/v3io/bigdata/netops_features_parquet\n",
    "\n",
    "\n",
    "# Parallelizem\n",
    "NUMBER_OF_SHARDS=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 22,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# DB Connection\n",
    "import v3io_frames as v3f\n",
    "\n",
    "# Parallelization\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 23,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_from_tsdb(context, df):\n",
    "    df.index.names = ['timestamp', 'company', 'data_center', 'device']\n",
    "    df = df.reset_index()\n",
    "    df = dd.from_pandas(df, npartitions=context.shards)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 24,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsdb(context):\n",
    "    df = context.v3f.read(backend='tsdb', query=f'select cpu_utilization, latency, packet_loss, throughput, is_error from {context.metrics_table}',\n",
    "                          start=f'now-2h', end='now', multi_index=True)\n",
    "    df = format_df_from_tsdb(context, df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 25,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_parquet(context):\n",
    "    # Get parquet files\n",
    "    mpath = [os.path.join(context.metrics_table, file) for file in os.listdir(context.metrics_table)]\n",
    "    \n",
    "    # Get latest filename\n",
    "    latest = max(mpath, key=os.path.getmtime)\n",
    "    \n",
    "    # Load parquet\n",
    "    df = pd.read_parquet(latest)\n",
    "    \n",
    "    # To Dask\n",
    "    df = format_df_from_tsdb(context, df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 26,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_featuers(context, df, window_size: int):\n",
    "    features = df.copy()\n",
    "    features['key'] = features.apply(lambda row: f'{row[\"company\"]}_{row[\"data_center\"]}_{row[\"device\"]}', axis=1, meta=features.compute().dtypes)\n",
    "    features.set_index('key')\n",
    "    features[\"cpu_utilization\"] = features.cpu_utilization.rolling(window=window_size).mean()\n",
    "    features[\"latency\"] = features.latency.rolling(window=window_size).mean()\n",
    "    features[\"packet_loss\"] = features.packet_loss.rolling(window=window_size).mean()\n",
    "    features[\"throughput\"] = features.throughput.rolling(window=window_size).mean()\n",
    "    features[\"is_error\"] = features.is_error.rolling(window=window_size).max()\n",
    "                                     \n",
    "    features = features.dropna()\n",
    "    features = features.drop_duplicates()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 27,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_indexes(df):\n",
    "    df = df.set_index(['timestamp', 'company', 'data_center', 'device'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 28,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_tsdb(context, features: pd.DataFrame):   \n",
    "    context.v3f.write('tsdb', context.features_table, features)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 29,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_parquet(context, df: pd.DataFrame):\n",
    "    print('Saving features to Parquet')\n",
    "    \n",
    "    # Need to fix timestamps from ns to ms if we write to parquet\n",
    "    df = df.reset_index()\n",
    "    df['timestamp'] = df.loc[:, 'timestamp'].astype('datetime64[ms]')\n",
    "    \n",
    "    # Fix indexes\n",
    "    df= set_indexes(df)\n",
    "    \n",
    "    # Save parquet\n",
    "    first_timestamp = df.index[0][0].strftime('%Y%m%dT%H%M%S')\n",
    "    last_timestamp = df.index[-1][0].strftime('%Y%m%dT%H%M%S')\n",
    "    filename = first_timestamp + '-' + last_timestamp + '.parquet'\n",
    "    filepath = os.path.join(context.features_table, filename)\n",
    "    with open(filepath, 'wb+') as f:\n",
    "        df.to_parquet(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init context"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 35,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    \n",
    "    # Create Dask client\n",
    "    dask_client = Client()\n",
    "    setattr(context, 'dask', dask_client)  \n",
    "    \n",
    "    # Dask shards / CV\n",
    "    setattr(context, 'shards', int(os.getenv('NUMBER_OF_SHARDS', 4)))\n",
    "    \n",
    "    # Get saving configuration\n",
    "    is_save_to_tsdb = (int(os.getenv('SAVE_TO_TSDB', 1)) == 1)\n",
    "    \n",
    "    # Netops metrics table\n",
    "    setattr(context, 'metrics_table', os.getenv('METRICS_TABLE', 'netops_metrics'))\n",
    "    \n",
    "    # Netops feautres table\n",
    "    setattr(context, 'features_table', os.getenv('FEATURES_TABLE', 'netops_features'))\n",
    "    \n",
    "    \n",
    "    # Save to TSDB\n",
    "    if is_save_to_tsdb:\n",
    "        # Create our DB client\n",
    "        v3io_client = v3f.Client(address='framesd:8081', \n",
    "                            container='bigdata', \n",
    "                            password=os.environ['V3IO_ACCESS_KEY'], \n",
    "                            user=os.environ['V3IO_USERNAME'])\n",
    "        setattr(context, 'v3f', v3io_client)\n",
    "        \n",
    "        # Create features table if neede\n",
    "        context.v3f.create('tsdb', context.features_table, attrs={'rate': '1/s'}, if_exists=1)\n",
    "        \n",
    "        # Set TSDB reading function\n",
    "        setattr(context, 'read', get_data_tsdb)\n",
    "        \n",
    "        # Set TSDB saving function\n",
    "        setattr(context, 'write', save_to_tsdb)\n",
    "        \n",
    "    # Save to Parquet\n",
    "    else:\n",
    "         # Create saving directory if needed\n",
    "        filepath = os.path.join(context.features_table)\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "            \n",
    "        # Set Parquet reading function\n",
    "        setattr(context, 'read', get_data_parquet)\n",
    "        \n",
    "        # Set Parquet saving function\n",
    "        setattr(context, 'write', save_to_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 42,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    \n",
    "    # Get data\n",
    "    raw = context.read(context) \n",
    "        \n",
    "    # Get minute features\n",
    "    minute = create_rolling_featuers(context, raw, 3)\n",
    "    column_names = {'cpu_utilization': 'cpu_utilization_minutely',\n",
    "                    'latency': 'latency_minutely',\n",
    "                    'packet_loss': 'packet_loss_minutely',\n",
    "                    'throughput': 'throughput_minutely'}\n",
    "    minute = minute.rename(columns=column_names)\n",
    "    \n",
    "    # Get hour features\n",
    "    hour = create_rolling_featuers(context, raw, 3*60)\n",
    "    column_names = {'cpu_utilization': 'cpu_utilization_hourly',\n",
    "                    'latency': 'latency_hourly',\n",
    "                    'packet_loss': 'packet_loss_hourly',\n",
    "                    'throughput': 'throughput_hourly'}\n",
    "    hour = hour.rename(columns=column_names)\n",
    "    \n",
    "    # Create feature vector from data sources\n",
    "    features_rm = raw.merge(minute, on=['timestamp', 'company', 'data_center', 'device'], suffixes=('_raw', '_minute'))\n",
    "    features_rm.compute()\n",
    "    \n",
    "    features = features_rm.merge(hour, on=['timestamp', 'company', 'data_center', 'device'], suffixes=('_raw', '_hourly'))\n",
    "    features = features.compute()\n",
    "    \n",
    "    # Save feature vector to TSDB\n",
    "    \n",
    "    # Drop key columns\n",
    "    features = features.reset_index(drop=True)\n",
    "    feature_cols = [col for col in features.columns if 'key' in col]\n",
    "    features = features.drop(feature_cols, axis=1)\n",
    "    \n",
    "    \n",
    "    # Fix indexes before saving\n",
    "    features = features.set_index(['timestamp', 'company', 'data_center', 'device'])\n",
    "    \n",
    "    # Save to TSDB\n",
    "    context.write(context, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.6/site-packages/bokeh/themes/theme.py:94: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  json = yaml.load(f)\n"
     ]
    }
   ],
=======
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
>>>>>>> origin/netops
   "source": [
    "# nuclio: ignore\n",
    "init_context(context)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 49,
>>>>>>> origin/netops
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'netops_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4fcaa9fd0c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# init_context(context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnuclio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f6b81865274a>\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(context, event)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Get data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Get minute features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d6216bcb2f7a>\u001b[0m in \u001b[0;36mget_data_parquet\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Get parquet files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get latest filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'netops_metrics'"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "# init_context(context)\n",
    "event = nuclio.Event(body='')\n",
    "output = handler(context, event)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nuclio.deploy] 2019-06-20 14:45:37,706 (info) Building processor image\n",
      "[nuclio.deploy] 2019-06-20 14:45:43,756 (info) Pushing image\n",
      "[nuclio.deploy] 2019-06-20 14:45:43,757 (info) Build complete\n",
      "[nuclio.deploy] 2019-06-20 14:45:49,813 (info) Function deploy complete\n",
      "[nuclio.deploy] 2019-06-20 14:45:49,818 done updating preprocessing, function address: 18.185.111.133:31293\n",
      "%nuclio: function deployed\n"
     ]
    }
   ],
   "source": [
    "%nuclio deploy -p netops -n PreProcessing -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
