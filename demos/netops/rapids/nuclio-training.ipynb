{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclio - Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.triggers.retrain.kind to 'cron'\n",
      "%nuclio: setting spec.triggers.retrain.attributes.interval to '1h'\n",
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config\n",
    "\n",
    "# Trigger\n",
    "spec.triggers.retrain.kind = \"cron\"\n",
    "spec.triggers.retrain.attributes.interval = \"1h\"\n",
    "\n",
    "# Base image\n",
    "spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /conda/envs/rapids/lib/python3.6/site-packages (5.1)\n",
      "Requirement already up-to-date: pyarrow in /conda/envs/rapids/lib/python3.6/site-packages (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /conda/envs/rapids/lib/python3.6/site-packages (from pyarrow) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.0.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pyarrow) (1.12.0)\n",
      "Requirement already satisfied: fastparquet in /conda/envs/rapids/lib/python3.6/site-packages (0.3.1)\n",
      "Requirement already satisfied: numba>=0.28 in /conda/envs/rapids/lib/python3.6/site-packages (from fastparquet) (0.41.0)\n",
      "Requirement already satisfied: thrift>=0.11.0 in /conda/envs/rapids/lib/python3.6/site-packages (from fastparquet) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /conda/envs/rapids/lib/python3.6/site-packages (from fastparquet) (1.16.2)\n",
      "Requirement already satisfied: pandas>=0.19 in /conda/envs/rapids/lib/python3.6/site-packages (from fastparquet) (0.23.4)\n",
      "Requirement already satisfied: six in /conda/envs/rapids/lib/python3.6/site-packages (from fastparquet) (1.12.0)\n",
      "Requirement already satisfied: llvmlite>=0.26.0dev0 in /conda/envs/rapids/lib/python3.6/site-packages (from numba>=0.28->fastparquet) (0.27.0.dev0+19.g6044afe)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pandas>=0.19->fastparquet) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /conda/envs/rapids/lib/python3.6/site-packages (from pandas>=0.19->fastparquet) (2019.1)\n",
      "Requirement already satisfied: pandas in /conda/envs/rapids/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pandas) (1.16.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /conda/envs/rapids/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /conda/envs/rapids/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: joblib in /conda/envs/rapids/lib/python3.6/site-packages (0.13.2)\n",
      "Requirement already up-to-date: v3io_frames in /conda/envs/rapids/lib/python3.6/site-packages (0.5.4)\n",
      "Requirement already satisfied, skipping upgrade: pandas==0.23.* in /conda/envs/rapids/lib/python3.6/site-packages (from v3io_frames) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio-tools>=1.16.0 in /conda/envs/rapids/lib/python3.6/site-packages (from v3io_frames) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos>=1.5.3 in /conda/envs/rapids/lib/python3.6/site-packages (from v3io_frames) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.1 in /conda/envs/rapids/lib/python3.6/site-packages (from v3io_frames) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pandas==0.23.*->v3io_frames) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pandas==0.23.*->v3io_frames) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /conda/envs/rapids/lib/python3.6/site-packages (from pandas==0.23.*->v3io_frames) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.5.0.post1 in /conda/envs/rapids/lib/python3.6/site-packages (from grpcio-tools>=1.16.0->v3io_frames) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.21.1 in /conda/envs/rapids/lib/python3.6/site-packages (from grpcio-tools>=1.16.0->v3io_frames) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /conda/envs/rapids/lib/python3.6/site-packages (from requests>=2.19.1->v3io_frames) (1.25.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /conda/envs/rapids/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.23.*->v3io_frames) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /conda/envs/rapids/lib/python3.6/site-packages (from protobuf>=3.5.0.post1->grpcio-tools>=1.16.0->v3io_frames) (41.0.1)\n",
      "Requirement already satisfied: scikit-learn==0.20.1 in /conda/envs/rapids/lib/python3.6/site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /conda/envs/rapids/lib/python3.6/site-packages (from scikit-learn==0.20.1) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /conda/envs/rapids/lib/python3.6/site-packages (from scikit-learn==0.20.1) (1.3.0)\n",
      "Requirement already up-to-date: xgboost in /conda/envs/rapids/lib/python3.6/site-packages (0.90)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /conda/envs/rapids/lib/python3.6/site-packages (from xgboost) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /conda/envs/rapids/lib/python3.6/site-packages (from xgboost) (1.16.2)\n",
      "Requirement already up-to-date: dask-ml[complete] in /conda/envs/rapids/lib/python3.6/site-packages (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: numba in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.41.0)\n",
      "Requirement already satisfied, skipping upgrade: dask-glm in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.20.1)\n",
      "Requirement already satisfied, skipping upgrade: distributed>=1.25.0 in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (1.28.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (19.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.23.4 in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: dask[array]>=1.0.0 in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: multipledispatch>=0.4.9 in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: xgboost; extra == \"complete\" in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.90)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow; extra == \"complete\" in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: dask-tensorflow; extra == \"complete\" in /conda/envs/rapids/lib/python3.6/site-packages (from dask-ml[complete]) (0.0.2)\n",
      "Requirement already satisfied, skipping upgrade: dask-xgboost; extra == \"complete\" in /conda/envs/rapids/lib/python3.6/site-packages/dask_xgboost-0.1.5-py3.6.egg (from dask-ml[complete]) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite>=0.26.0dev0 in /conda/envs/rapids/lib/python3.6/site-packages (from numba->dask-ml[complete]) (0.27.0.dev0+19.g6044afe)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.2 in /conda/envs/rapids/lib/python3.6/site-packages (from dask-glm->dask-ml[complete]) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: msgpack in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5 in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (5.1.1)\n",
      "Requirement already satisfied, skipping upgrade: click>=6.6 in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (0.1.4)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tblib in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (5.6.2)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.7.4 in /conda/envs/rapids/lib/python3.6/site-packages (from distributed>=1.25.0->dask-ml[complete]) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /conda/envs/rapids/lib/python3.6/site-packages (from packaging->dask-ml[complete]) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /conda/envs/rapids/lib/python3.6/site-packages (from pandas>=0.23.4->dask-ml[complete]) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /conda/envs/rapids/lib/python3.6/site-packages (from pandas>=0.23.4->dask-ml[complete]) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow; extra == \"complete\"->dask-ml[complete]) (0.33.4)\n",
      "Requirement already satisfied, skipping upgrade: heapdict in /conda/envs/rapids/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=1.25.0->dask-ml[complete]) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /conda/envs/rapids/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow; extra == \"complete\"->dask-ml[complete]) (41.0.1)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow; extra == \"complete\"->dask-ml[complete]) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow; extra == \"complete\"->dask-ml[complete]) (0.15.4)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /conda/envs/rapids/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow; extra == \"complete\"->dask-ml[complete]) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /conda/envs/rapids/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow; extra == \"complete\"->dask-ml[complete]) (2.9.0)\n",
      "Requirement already satisfied: cuml in /conda/envs/rapids/lib/python3.6/site-packages (0.7.0+0.g82f147b.dirty)\n",
      "Requirement already satisfied: numpy in /conda/envs/rapids/lib/python3.6/site-packages (from cuml) (1.16.2)\n",
      "Requirement already satisfied: cython in /conda/envs/rapids/lib/python3.6/site-packages (from cuml) (0.29.7)\n"
     ]
    }
   ],
   "source": [
    "%%nuclio cmd \n",
    "\n",
    "############\n",
    "# installs #\n",
    "############\n",
    "\n",
    "# Utils\n",
    "pip install pyyaml\n",
    "pip install pyarrow --upgrade\n",
    "pip install fastparquet\n",
    "pip install pandas\n",
    "pip install joblib\n",
    "\n",
    "# Igz DB\n",
    "pip install v3io_frames --upgrade\n",
    "\n",
    "# Function\n",
    "pip install scikit-learn==0.20.1\n",
    "pip install xgboost --upgrade\n",
    "pip install dask-ml[\"complete\"] --upgrade\n",
    "pip install cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: V3IO_FRAMESD=''\n",
      "env: V3IO_USERNAME=''\n",
      "env: V3IO_ACCESS_KEY=''\n"
     ]
    }
   ],
   "source": [
    "%env V3IO_FRAMESD=''\n",
    "%env V3IO_USERNAME=''\n",
    "%env V3IO_ACCESS_KEY=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'V3IO_FRAMESD' environment variable\n",
      "%nuclio: setting 'V3IO_USERNAME' environment variable\n",
      "%nuclio: setting 'V3IO_ACCESS_KEY' environment variable\n",
      "%nuclio: setting '# FEATURES_TABLE' environment variable\n",
      "%nuclio: setting 'FEATURES_TABLE' environment variable\n",
      "%nuclio: setting 'FROM_TSDB' environment variable\n",
      "%nuclio: setting 'TRAIN_ON_LAST' environment variable\n",
      "%nuclio: setting 'TRAIN_SIZE' environment variable\n",
      "%nuclio: setting 'NUMBER_OF_SHARDS' environment variable\n",
      "%nuclio: setting 'MODEL_FILENAME' environment variable\n",
      "%nuclio: setting 'SAVE_TO' environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n",
      "%nuclio: cannot find \"=\" in line\n"
     ]
    }
   ],
   "source": [
    "%%nuclio env\n",
    "\n",
    "# DB Config\n",
    "V3IO_FRAMESD=${V3IO_FRAMESD}\n",
    "V3IO_USERNAME=${V3IO_USERNAME}\n",
    "V3IO_ACCESS_KEY=${V3IO_ACCESS_KEY}\n",
    "\n",
    "# Features\n",
    "# FEATURES_TABLE=/v3io/bigdata/netops_features_parquet\n",
    "FEATURES_TABLE=../netops_features\n",
    "FROM_TSDB=0\n",
    "\n",
    "# Training\n",
    "TRAIN_ON_LAST=1d\n",
    "TRAIN_SIZE=0.7\n",
    "\n",
    "# Parallelizem\n",
    "NUMBER_OF_SHARDS=4\n",
    "\n",
    "# Model\n",
    "MODEL_FILENAME=netops.v3.model\n",
    "SAVE_TO=../models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# DB Connection\n",
    "import v3io_frames as v3f\n",
    "import cudf\n",
    "\n",
    "# Parallelization\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import dask_cudf\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Function\n",
    "import dask_ml.model_selection as dcv\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_from_tsdb(context, df):\n",
    "    df.index.names = ['timestamp', 'company', 'data_center', 'device']\n",
    "    df = df.reset_index()\n",
    "    df = dd.from_pandas(df, npartitions=context.shards)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsdb(context):\n",
    "    df = context.v3f.read(backend='tsdb', query=f'select * from {context.features_table}',\n",
    "                          start=f'now-{context.train_on_last}', end='now', multi_index=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[sorted(df.columns)]\n",
    "    dd.from_pandas\n",
    "    df = dd.from_pandas(df, npartitions=context.shards)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_parquet(context):\n",
    "    # Get parquet files\n",
    "    mpath = [os.path.join(context.features_table, file) for file in os.listdir(context.features_table)]\n",
    "    \n",
    "    # Get latest filename\n",
    "    latest = max(mpath, key=os.path.getmtime)\n",
    "    print(latest)\n",
    "    context.logger.debug(f'Reading data from: {latest}')\n",
    "    \n",
    "    # Load parquet to dask\n",
    "#     df = dd.read_parquet(latest, engine='fastparquet')\n",
    "    df = cudf.read_parquet(latest)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets_from_data(context, df):\n",
    "    drop_columns = [col for col in df.columns if 'is_error' in col]\n",
    "    index_columns = ['timestamp', 'company', 'data_center', 'device']\n",
    "    X = df.drop(drop_columns + index_columns, axis=1)\n",
    "    X = X[sorted(X.columns)]\n",
    "    y = df.loc[:, ['is_error']]['is_error'].astype(bool)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=context.train_size, test_size=1-context.train_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_context(context):\n",
    "    \n",
    "    # Netops features table\n",
    "    setattr(context, 'features_table', os.getenv('FEATURES_TABLE', 'netops_features'))\n",
    "    \n",
    "    # Get saving configuration\n",
    "    is_from_tsdb = (int(os.getenv('FROM_TSDB', 1)) == 1)\n",
    "    \n",
    "    # Save to TSDB\n",
    "    if is_from_tsdb:\n",
    "        # Create our DB client\n",
    "        v3io_client = v3f.Client(address='http://' + os.getenv('V3IO_FRAMESD', 'framesd:8081'), \n",
    "                            container='bigdata', \n",
    "                            password=os.environ['V3IO_ACCESS_KEY'], \n",
    "                            user=os.environ['V3IO_USERNAME'])\n",
    "        setattr(context, 'v3f', v3io_client)\n",
    "        \n",
    "        # Create features table if neede\n",
    "        context.v3f.create('tsdb', context.features_table, attrs={'rate': '1/s'}, if_exists=1)\n",
    "        \n",
    "        # Set TSDB reading function\n",
    "        setattr(context, 'read', get_data_tsdb)\n",
    "        \n",
    "    # Save to Parquet\n",
    "    else:\n",
    "         # Create saving directory if needed\n",
    "        filepath = os.path.join(context.features_table)\n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "            \n",
    "        # Set Parquet reading function\n",
    "        setattr(context, 'read', get_data_parquet)\n",
    "    \n",
    "    # Set time to train on\n",
    "    train_on_last = os.getenv('TRAIN_ON_LAST', '7d')\n",
    "    setattr(context, 'train_on_last', train_on_last)\n",
    "    \n",
    "    # Set training set size\n",
    "    train_set_size = float(os.getenv('TRAIN_SIZE', 0.7))\n",
    "    setattr(context, 'train_size', train_set_size)\n",
    "    \n",
    "    # Dask shards / CV\n",
    "    setattr(context, 'shards', int(os.getenv('NUMBER_OF_SHARDS', 4)))\n",
    "    \n",
    "    # Create save-to folder if needed\n",
    "    model_filepath = os.getenv('SAVE_TO', '/v3io/bigdata/netops/models')\n",
    "    if not os.path.exists(model_filepath):\n",
    "        os.makedirs(model_filepath)\n",
    "    setattr(context, 'model_filepath', os.path.join(model_filepath, os.getenv('MODEL_FILENAME', 'netops.model')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    \n",
    "    # Get data\n",
    "    df = context.read(context) \n",
    "\n",
    "    # Split to Train / Test datasets\n",
    "    X_train, X_test, y_train, y_test = get_train_test_sets_from_data(context, df)\n",
    "    \n",
    "    train = xgb.DMatrix(data=X_train.as_gpu_matrix(), label=y_train)\n",
    "    test = xgb.DMatrix(data=X_test.as_gpu_matrix(), label=y_test)\n",
    "        \n",
    "    # Train\n",
    "    params = {'objective': 'binary:logistic', # Specify multiclass classification\n",
    "             'tree_method': 'gpu_hist' # Use GPU accelerated algorithm\n",
    "    }\n",
    "    \n",
    "    res = {}\n",
    "    model = xgb.train(params, train, evals=[(test, 'test')], evals_result=res)\n",
    "    print(res)\n",
    "    context.logger.debug(f'test results: {res}')\n",
    "    \n",
    "    # Save model\n",
    "    pickle.dump(model, open(context.model_filepath + '.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "init_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../netops_features/20190606T080717-20190607T080527.parquet\n",
      "[0]\ttest-error:0.046933\n",
      "[1]\ttest-error:0.044132\n",
      "[2]\ttest-error:0.044567\n",
      "[3]\ttest-error:0.042032\n",
      "[4]\ttest-error:0.04167\n",
      "[5]\ttest-error:0.041283\n",
      "[6]\ttest-error:0.040945\n",
      "[7]\ttest-error:0.039714\n",
      "[8]\ttest-error:0.039038\n",
      "[9]\ttest-error:0.038942\n",
      "{'test': {'error': [0.046933, 0.044132, 0.044567, 0.042032, 0.04167, 0.041283, 0.040945, 0.039714, 0.039038, 0.038942]}}\n"
     ]
    }
   ],
   "source": [
    "# nuclio: ignore\n",
    "# init_context(context)\n",
    "event = nuclio.Event(body='')\n",
    "output = handler(context, event)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: ['deploy', '-p', 'netops', '-n', 'training', '-c', '/User/netops/tutorials/demos/netops/Nuclio-Training.ipynb']\n",
      "%nuclio: [nuclio.deploy] 2019-05-20 10:54:16,684 (info) Building processor image\n",
      "%nuclio: [nuclio.deploy] 2019-05-20 10:54:24,902 (info) Pushing image\n",
      "%nuclio: [nuclio.deploy] 2019-05-20 10:54:24,902 (info) Build complete\n",
      "%nuclio: [nuclio.deploy] 2019-05-20 10:54:36,603 done updating training, function address: 3.122.56.83:32342\n",
      "%nuclio: function deployed\n"
     ]
    }
   ],
   "source": [
    "%nuclio deploy -p netops -n training -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
